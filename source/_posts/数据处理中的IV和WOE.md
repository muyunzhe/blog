---
title: 数据处理中的IV和WOE
comments: true
toc: true
mathjax2: true
keywords: '牧云者,人工智能,云计算,数据挖掘,hexo,blog'
categories: [artificial-intelligence,machine-learning]
tags: [machine-learning,AUC]
date: 2017-05-31 20:43:57
---
我们在用逻辑回归、决策树等模型方法构建分类模型时，经常需要对自变量进行筛选。比如我们有200个候选自变量，通常情况下，不会直接把200个变量直接放到模型中去进行拟合训练，而是会用一些方法，从这200个自变量中挑选一些出来，放进模型，形成入模变量列表。那么我们怎么去挑选入模变量呢？
 <!--more-->
 挑选入模变量过程是个比较复杂的过程，需要考虑的因素很多，比如：变量的预测能力，变量之间的相关性，变量的简单性（容易生成和使用），变量的强壮性（不容易被绕过），变量在业务上的可解释性（被挑战时可以解释的通）等等。但是，其中最主要和最直接的衡量标准是变量的预测能力。
 怎么去评价一个变量的预测能力呢？
 ## IV
对于一个待预测的个体A，要判断A属于Y1还是Y2，我们是需要一定的信息的，假设这个信息总量是I，而这些所需要的信息，就蕴含在所有的自变量C1，C2，C3，……，Cn中，那么，对于其中的一个变量Ci来说，其蕴含的信息越多，那么它对于判断A属于Y1还是Y2的贡献就越大，Ci的信息价值就越大，Ci的IV就越大。
 对于一个待评估变量，他的IV值究竟如何计算呢？为了介绍IV的计算方法，我们首先需要认识和理解另一个概念——WOE，因为IV的计算是以WOE为基础的。
 ### woe
 WOE的全称是“Weight of Evidence”，即证据权重。WOE是对原始自变量的一种编码形式。实际上是“当前分组中响应客户占所有响应客户的比例”和“当前分组中没有响应的客户占所有没有响应的客户的比例”的差异。
