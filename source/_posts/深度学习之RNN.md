---
title: 深度学习之RNN
comments: true
toc: true
mathjax2: true
date: 2018-01-22 16:47:05
categories: [artificial-intelligence,deep-learning]
tags: [deep-learning,Neural Networks]
keywords: '牧云者,人工智能,云计算,数据挖掘,hexo,blog'
---
通常的深度学习模型都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理序列的信息，即前面的输入和后面的输入是有关系的。
 <!--more-->
## RNN结构

 ![RNN结构](/img/RNN结构.jpg)
 x是一个向量，它表示输入层的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示隐藏层的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；U是输入层到隐藏层的权重矩阵（读者可以回到第三篇文章零基础入门深度学习(3) - 神经网络和反向传播算法，看看我们是怎样用矩阵来表示全连接神经网络的计算的）；o也是一个向量，它表示输出层的值；V是隐藏层到输出层的权重矩阵。那么，现在我们来看看W是什么。循环神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重矩阵 W就是隐藏层上一次的值作为这一次的输入的权重。
 这个网络在t时刻接收到输入之后，隐藏层的值是，输出值是。

### N vs 1
输入是一个序列，输出是一个单独的值而不是序列
![](/img/n21.jpg)
这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。

### 1 VS N
输入不是序列而输出为序列的情况怎么处理？我们可以只在序列开始进行输入计算：
![](/img/12n.jpg)

这种1 VS N的结构可以处理的问题有：
从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子
从类别生成语音或音乐等

### N VS M
这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。
原始的N vs N RNN要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。
为此，Encoder-Decoder结构先将输入数据编码成一个上下文向量c：
![](/img/N2M1.jpg)
得到c有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换。

拿到c之后，就用另一个RNN网络对其进行解码，这部分RNN网络被称为Decoder。具体做法就是将c当做之前的初始状态h0输入到Decoder中：
![](/img/N2M2.jpg)
由于这种Encoder-Decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：
1. 机器翻译。Encoder-Decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的
2. 文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。
3. 阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。
4. 语音识别。输入是语音信号序列，输出是文字序列。
5. …………

## Attention机制
在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。
Attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有Attention机制的Decoder：
![](/img/attention.jpg)
每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用 a_{ij} 衡量Encoder中第j阶段的hj和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息 c_i 就来自于所有 h_j 对 a_{ij} 的加权和。
事实上， a_{ij} 同样是从模型中学出的，它实际和Decoder的第i-1阶段的隐状态、Encoder第j个阶段的隐状态有关。
