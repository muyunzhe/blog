---
title: GBDT+LR模型实现离线+实时特征层次化预测
comments: true
toc: true
mathjax2: true
keywords: '牧云者,人工智能,云计算,数据挖掘,hexo,blog'
date: 2017-06-01 15:19:57
categories: [artificial-intelligence,machine-learning]
tags: [machine-learning,classification]
---
特征决定了所有算法效果的上限，而不同的算法只是离这个上限的距离不同而已。
 <!--more-->
 本文中我将介绍Facebook发表的利用GBDT模型构造新特征的方法。

论文的思想很简单，就是先用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。

举例说明。下面的图中的两棵树是GBDT学习到的，第一棵树有3个叶子结点，而第二棵树有2个叶子节点。对于一个输入样本点x，如果它在第一棵树最后落在其中的第二个叶子结点，而在第二棵树里最后落在其中的第一个叶子结点。那么通过GBDT获得的新特征向量为[0, 1, 0, 1, 0]，其中向量中的前三位对应第一棵树的3个叶子结点，后两位对应第二棵树的2个叶子结点。
[Hybrid model structure](/img/fb_gbdt1.png)

那么，GBDT中需要多少棵树能达到效果最好呢？具体数字显然是依赖于你的应用以及你拥有的数据量。一般数据量较少时，树太多会导致过拟合。在作者的应用中，大概500棵左右效果就基本不改进了。另外，作者在建GBDT时也会对每棵树的叶子结点数做约束——不多于12个叶子结点。
